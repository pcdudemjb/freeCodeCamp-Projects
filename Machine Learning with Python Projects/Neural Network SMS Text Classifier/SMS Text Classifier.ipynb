{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6adbdd-3e14-4d14-90be-4b2a634dc0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0-dev20240303\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "# try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "#    !pip install tf-nightly\n",
    "# except Exception:\n",
    "#    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "# !pip install tensorflow-datasets\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2046ecbd-3fa7-4410-b143-6984eabe0655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve data files\n",
    "# !wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
    "# !wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
    "\n",
    "train_file_path = \"train-data.tsv\"\n",
    "test_file_path = \"valid-data.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e73be48-72ac-444d-8e63-ebfbbb427601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframes from tsv files\n",
    "df_train = pd.read_csv(train_file_path, sep = '\\t', header = None, names = ['label', 'text'])\n",
    "df_test = pd.read_csv(test_file_path, sep = '\\t', header = None, names = ['label', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e60cf4e-4b96-46f2-b335-3ee06a4e8083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>ahhhh...just woken up!had a bad dream about u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>you can never do nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>now u sound like manky scouse boy steve,like! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>mum say we wan to go then go... then she can s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>never y lei... i v lazy... got wat? dat day ü ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  ahhhh...just woken up!had a bad dream about u ...\n",
       "1   ham                           you can never do nothing\n",
       "2   ham  now u sound like manky scouse boy steve,like! ...\n",
       "3   ham  mum say we wan to go then go... then she can s...\n",
       "4   ham  never y lei... i v lazy... got wat? dat day ü ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ff21539-ef6e-4555-923b-5f879bb78952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>i am in hospital da. . i will return home in e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>not much, just some textin'. how bout you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>i probably won't eat at all today. i think i'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>don‘t give a flying monkeys wot they think and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>who are you seeing?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  i am in hospital da. . i will return home in e...\n",
       "1   ham         not much, just some textin'. how bout you?\n",
       "2   ham  i probably won't eat at all today. i think i'm...\n",
       "3   ham  don‘t give a flying monkeys wot they think and...\n",
       "4   ham                                who are you seeing?"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6608f4f0-0daf-4cda-bf71-35d60a293121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4179\n",
      "1392\n"
     ]
    }
   ],
   "source": [
    "# Printing number of rows from each dataframe\n",
    "print(len(df_train))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3fc4642-fd58-4c50-9926-cd45ba3780ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting labels to integer\n",
    "df_train['label'] = df_train['label'].replace(to_replace = {'ham': 0, 'spam': 1})\n",
    "df_test['label'] = df_test['label'].replace(to_replace = {'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df481922-490d-4359-85ef-d5a6bb5e3f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8810b1ce-06de-4820-bad2-5b5fda4adca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01fc5d3f-488b-4e34-b871-c63dad4e839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910\n"
     ]
    }
   ],
   "source": [
    "# Determining length of longest text (df_train)\n",
    "train_msg_len = df_train['text'].apply(len)\n",
    "print(max(train_msg_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "579ebf04-af33-4e3f-ac3d-c28c25d12640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482\n"
     ]
    }
   ],
   "source": [
    "# Determining length of longest text (df_test)\n",
    "test_msg_len = df_test['text'].apply(len)\n",
    "print(max(test_msg_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fd9b6db-8926-44f8-85aa-520a45483593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for text preprocessing and model training\n",
    "MAXLEN = 250\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Fit the tokenizer on the training text data\n",
    "tokenizer.fit_on_texts(df_train['text'])\n",
    "\n",
    "# Calculate the vocabulary size based on the tokenizer's word index\n",
    "VOCAB_SIZE = len(tokenizer.word_index)\n",
    "\n",
    "# Convert text to sequences of integers\n",
    "train_sequences = tokenizer.texts_to_sequences(df_train['text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(df_test['text'])\n",
    "\n",
    "# Pad sequences\n",
    "train_sequences_padded = sequence.pad_sequences(train_sequences, maxlen = MAXLEN)\n",
    "test_sequences_padded = sequence.pad_sequences(test_sequences, maxlen = MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc60f3d-4bee-43fb-958d-45aae26f2d10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pcdud\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, BATCH_SIZE, input_shape = (MAXLEN,)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences = True)),\n",
    "    tf.keras.layers.LSTM(64, dropout = 0.2, recurrent_dropout = 0.2),\n",
    "    tf.keras.layers.Dense(1, activation = \"sigmoid\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03214b63-5fcd-4cd4-bcda-bd942061a2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">984,576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m984,576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,132,865</span> (4.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,132,865\u001b[0m (4.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,132,865</span> (4.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,132,865\u001b[0m (4.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 632ms/step - accuracy: 0.8182 - loss: 0.4492 - val_accuracy: 0.9701 - val_loss: 0.1150\n",
      "Epoch 2/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 628ms/step - accuracy: 0.9796 - loss: 0.0864 - val_accuracy: 0.9844 - val_loss: 0.0658\n",
      "Epoch 3/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 652ms/step - accuracy: 0.9913 - loss: 0.0371 - val_accuracy: 0.9856 - val_loss: 0.0577\n",
      "Epoch 4/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 670ms/step - accuracy: 0.9966 - loss: 0.0147 - val_accuracy: 0.9880 - val_loss: 0.0615\n",
      "Epoch 5/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 679ms/step - accuracy: 0.9948 - loss: 0.0205 - val_accuracy: 0.9856 - val_loss: 0.0547\n",
      "Epoch 6/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 661ms/step - accuracy: 0.9999 - loss: 0.0029 - val_accuracy: 0.9868 - val_loss: 0.0585\n",
      "Epoch 7/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 673ms/step - accuracy: 0.9996 - loss: 0.0038 - val_accuracy: 0.9880 - val_loss: 0.0591\n",
      "Epoch 8/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 664ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9892 - val_loss: 0.0608\n",
      "Epoch 9/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 683ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.9904 - val_loss: 0.0602\n",
      "Epoch 10/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 687ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.9880 - val_loss: 0.0656\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# View model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_sequences_padded, df_train['label'], \n",
    "                    batch_size = BATCH_SIZE, \n",
    "                    epochs = 10, \n",
    "                    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8872b55-f176-4c6a-a887-27f8d3f75d48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
      "[0.9928429, 'spam']\n"
     ]
    }
   ],
   "source": [
    "# Function to predict messages based on model\n",
    "# (Should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
    "def predict_message(pred_text):    \n",
    "    # Preprocess the input text\n",
    "    pred_sequence = tokenizer.texts_to_sequences([pred_text])\n",
    "    pred_sequence_padded = sequence.pad_sequences(pred_sequence, maxlen=MAXLEN)\n",
    "    \n",
    "    # Make predictions using the model\n",
    "    prediction = model.predict(pred_sequence_padded)\n",
    "    \n",
    "    # Convert prediction to label\n",
    "    label = \"ham\" if prediction < 0.5 else \"spam\"\n",
    "    \n",
    "    return [prediction[0][0], label]\n",
    "\n",
    "pred_text = \"sale today! to stop texts call 98912460324\"\n",
    "prediction = predict_message(pred_text)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bc6889a-a3a2-41ed-9506-3be728dcb157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "You passed the challenge. Great job!\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to test your function and model. Do not modify contents.\n",
    "def test_predictions():\n",
    "  test_messages = [\"how are you doing today\",\n",
    "                   \"sale today! to stop texts call 98912460324\",\n",
    "                   \"i dont want to go. can we try it a different day? available sat\",\n",
    "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
    "                   \"you have won £1000 cash! call to claim your prize.\",\n",
    "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
    "                   \"wow, is your arm alright. that happened to me one time too\"\n",
    "                  ]\n",
    "\n",
    "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
    "  passed = True\n",
    "\n",
    "  for msg, ans in zip(test_messages, test_answers):\n",
    "    prediction = predict_message(msg)\n",
    "    if prediction[1] != ans:\n",
    "      passed = False\n",
    "\n",
    "  if passed:\n",
    "    print(\"You passed the challenge. Great job!\")\n",
    "  else:\n",
    "    print(\"You haven't passed yet. Keep trying.\")\n",
    "\n",
    "test_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
